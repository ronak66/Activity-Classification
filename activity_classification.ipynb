{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processig and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_handling:\n",
    "\n",
    "    def __init__(self,file_path):\n",
    "        self.df = pd.read_csv(file_path)\n",
    "\n",
    "    def split_dataset_to_X_Y_Z(self,save_path,file_type):\n",
    "        df_name = pd.DataFrame(columns=range(21))\n",
    "        for col in ['X','Y','Z']:\n",
    "            k=0\n",
    "            for i in range(0,len(self.df[col]),20):\n",
    "                if(len(self.df[col][i:i+20].values)==20): \n",
    "                    df_name.loc[k] = np.append(self.df[col][i:i+20].values, self.df['y'][i])\n",
    "                    k+=1\n",
    "            df_name.to_csv(save_path+file_type+'_'+col+'.csv',index=False)\n",
    "        return\n",
    "\n",
    "    @staticmethod\n",
    "    def merge_csv():\n",
    "        for col in ['Accelerometer.csv','Gyroscope.csv']:\n",
    "            df_climb = pd.read_csv('Data/new/climbing_0/'+col)\n",
    "            df_jump = pd.read_csv('Data/new/jumping_1/'+col)\n",
    "            df_run = pd.read_csv('Data/new/running_2/'+col)\n",
    "            df_walk = pd.read_csv('Data/new/walking_3/'+col)\n",
    "            df = df_climb.append(df_jump.append(df_run.append(df_walk,ignore_index = True),ignore_index = True),ignore_index = True)\n",
    "            df.to_csv('Data/new/'+col,index=False)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "\n",
    "    def __init__(self,file_path):\n",
    "        (X,Y) = self.get_data(file_path)\n",
    "        self.kerras_classifier(X,Y)\n",
    "        return\n",
    "        \n",
    "\n",
    "    def get_data(self,file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        dataset = df.values\n",
    "\n",
    "        X = dataset[:,0:20].astype(float) # sensor data\n",
    "        Y = dataset[:,20].astype(int) # labels\n",
    "        return (X,Y)\n",
    "\n",
    "    def create_model(self):\n",
    "        # Define model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(22, input_dim=20, activation='relu'))\n",
    "        model.add(Dense(22, activation='relu'))\n",
    "        model.add(Dense(22, activation='relu'))\n",
    "        model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "        # Compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def kerras_classifier(self,X_train,Y_train):\n",
    "        self.model = KerasClassifier(self.create_model, epochs=200, batch_size=100, verbose=False)\n",
    "        self.model.fit(X_train, Y_train)\n",
    "        return self.model\n",
    "\n",
    "    def result(self,X_test,Y_test):\n",
    "        kfold = KFold(n_splits=10, shuffle=True, random_state=5)\n",
    "        cv_results = cross_val_score(self.model, X_test, Y_test, cv=kfold)\n",
    "        print(\"Baseline on test data: %.2f%% (%.2f%%)\" % (cv_results.mean()*100, cv_results.std()*100))\n",
    "        return cv_results\n",
    "\n",
    "    def predict(self,X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class activity_classifier:\n",
    "\n",
    "    def __init__(self):\n",
    "        print('training model 1'+'-'*50)\n",
    "        self.acc_x_model = Model('Data/new/acc_X.csv')\n",
    "        print('training model 2'+'-'*50)\n",
    "        self.acc_y_model = Model('Data/new/acc_Y.csv')\n",
    "        print('training model 3'+'-'*50)\n",
    "        self.acc_z_model = Model('Data/new/acc_Z.csv')\n",
    "        print('training model 4'+'-'*50)\n",
    "        self.gyro_x_model = Model('Data/new/gyro_X.csv')\n",
    "        print('training model 5'+'-'*50)\n",
    "        self.gyro_y_model = Model('Data/new/gyro_Y.csv')\n",
    "        print('training model 6'+'-'*50)\n",
    "        self.gyro_z_model = Model('Data/new/gyro_Z.csv')\n",
    "        return\n",
    "\n",
    "    def accuracy(self):\n",
    "        print('Calculating Accuracy'+'-'*50)\n",
    "        df_acc = pd.read_csv('Data/new/Accelerometer.csv')\n",
    "        df_gyro = pd.read_csv('Data/new/Gyroscope.csv')\n",
    "        count=0\n",
    "        total=0\n",
    "        confussion = [\n",
    "            [0,0,0,0],\n",
    "            [0,0,0,0],\n",
    "            [0,0,0,0],\n",
    "            [0,0,0,0]\n",
    "        ]\n",
    "        \n",
    "        for i in range(0,len(df_acc['X']),20):\n",
    "            if(len(df_acc['X'][i:i+20].values)==20):\n",
    "                p_acc_x = self.acc_x_model.predict(np.asarray([df_acc['X'][i:i+20].values]))\n",
    "                p_acc_y = self.acc_y_model.predict(np.asarray([df_acc['Y'][i:i+20].values]))\n",
    "                p_acc_z = self.acc_z_model.predict(np.asarray([df_acc['Z'][i:i+20].values]))\n",
    "                p_gyro_x = self.gyro_x_model.predict(np.asarray([df_gyro['X'][i:i+20].values]))\n",
    "                p_gyro_y = self.gyro_y_model.predict(np.asarray([df_gyro['Y'][i:i+20].values]))\n",
    "                p_gyro_z = self.gyro_z_model.predict(np.asarray([df_gyro['Z'][i:i+20].values]))\n",
    "                prediction = self.mode([p_acc_x[0],p_acc_y[0],p_acc_z[0],p_gyro_x[0],p_gyro_y[0],p_gyro_z[0]])\n",
    "                if(df_acc['y'][i] == prediction):\n",
    "                    count+=1\n",
    "                total+=1\n",
    "                confussion[df_acc['y'][i]][prediction] += 1\n",
    "        return ((count/total)*100,confussion)\n",
    "\n",
    "    def mode(self,array):\n",
    "        return max(set(array), key = array.count) \n",
    "        # np.bincount(array).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model 1--------------------------------------------------\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "training model 2--------------------------------------------------\n",
      "training model 3--------------------------------------------------\n",
      "training model 4--------------------------------------------------\n",
      "training model 5--------------------------------------------------\n",
      "training model 6--------------------------------------------------\n",
      "Calculating Accuracy--------------------------------------------------\n",
      "\n",
      " -------------------------------------------------------------------------------\n",
      "|                         Accuracy of the model:  96.12359550561797                         |\n",
      " -------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "models = activity_classifier()\n",
    "result = models.accuracy()\n",
    "print()\n",
    "print(' '+'-'*79)\n",
    "print('|' + ' '*25 +'Accuracy of the model:  '+str(result[0])+ ' '*25+'|')\n",
    "print(' '+'-'*79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412  2  0  16  \n",
      "5  351  1  13  \n",
      "0  5  429  1  \n",
      "22  4  0  519  \n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        print(str(result[1][i][j]),end=\"  \")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
